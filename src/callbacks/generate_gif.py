# src/callbacks/generate_gif.py
import math, torch, imageio
from pathlib import Path
from pytorch_lightning.utilities import rank_zero_only

class GenerateGif:
    """
    æ¯ N æ­¥æŠŠå½“å‰æ¨¡å‹æƒé‡æ‹‰å‡ºæ¥ï¼Œ
    ç”¨ encoder_visualizer æ¸²æŸ“ 360Â° ç¯å½¢è§†è§’ GIFã€‚
    """
    def __init__(self,
                 output_dir="outputs/gif",
                 n_frames=60,
                 fps=10,
                 dist=2.0,
                 elev=20.,
                 h=176,
                 w=176):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True, parents=True)
        self.n_frames = n_frames
        self.fps = fps
        self.dist, self.elev = dist, elev
        self.h, self.w = h, w

    # --------------------------------------------------
    @rank_zero_only          # å¤šå¡æ—¶åªè®©ä¸»è¿›ç¨‹åšå¯è§†åŒ–
    def generate(self, trainer, pl_module):
        device = pl_module.device
        pl_module.eval()

        images = []
        with torch.no_grad():
            for i in range(self.n_frames):
                azim = i * (360 / self.n_frames)
                camera = self._build_camera(device, azim)

                # 1. æ„é€ æç®€ batchï¼ˆåªç»™ encoder ç”¨ï¼‰
                # æ„é€ æç®€ batchï¼ˆä¸ grid batch ç»´åº¦ä¸€è‡´ï¼‰
                dummy_img = torch.zeros(2, 1, 3, self.h, self.w, device=device)

                # å¤–å‚ [1, 1, 4, 4]
                extrinsics_4x4 = torch.eye(4, device=device).unsqueeze(0).unsqueeze(0)
                extrinsics_4x4[:, 0, :3, :3] = camera["R"]  # [1, 3, 3]
                extrinsics_4x4[:, 0, :3, 3]  = camera["t"]  # [1, 3]

                # å†…å‚ [1, 3, 3]  â†ğŸ”¥FIX  åª unsqueeze ä¸€æ¬¡
                # intrinsics = camera["K"].unsqueeze(0)
                # å†…å‚ [1, 3, 3]
                intrinsics = camera["K"].unsqueeze(0)  # å¿…é¡»æ˜¯ [3, 3] å‰æ

                batch = {
                    "context": {
                        "image": dummy_img,
                        "camera": camera,
                        "extrinsics": extrinsics_4x4,
                        # "intrinsics": intrinsics.unsqueeze(0),  # ğŸ”¥å†è¡¥ä¸€ç»´ â†’ [1, 1, 3, 3]
                        "intrinsics": intrinsics,  # [1, 3, 3]
                        "near": torch.tensor([[0.1]], device=device),
                        "far":  torch.tensor([[10.0]], device=device),
                        "index": torch.tensor([[0]], device=device),
                    },
                    "target": {
                        "image": dummy_img,
                        "camera": camera,
                        "extrinsics": extrinsics_4x4,
                        "intrinsics": intrinsics.unsqueeze(0),  # ğŸ”¥åŒä¸Š
                        "near": torch.tensor([[0.1]], device=device),
                        "far":  torch.tensor([[10.0]], device=device),
                        "index": torch.tensor([[0]], device=device),
                    }
                }

                # 2. å‰å‘ -> é«˜æ–¯
                gaussians, _ = pl_module(batch)   # è¿”å› (gaussians, extra)

                # 3. visualizer æ¸²æŸ“
                vis = pl_module.encoder_visualizer
                pred = vis.render_panorama(gaussians,
                                           camera,
                                           (self.h, self.w))   # [1,3,H,W] 0-1
                img = pred[0].clamp(0, 1)
                img = (img * 255).byte().cpu().numpy().transpose(1, 2, 0)
                images.append(img)

        # 4. ä¿å­˜ gif
        step = trainer.global_step
        gif_path = self.output_dir / f"step{step:06d}.gif"
        imageio.mimsave(gif_path, images, fps=self.fps)
        print(f"[GenerateGif] ç¯å½¢è§†è§’ gif å·²ä¿å­˜ â†’ {gif_path}")

        pl_module.train()          # åˆ«å¿˜äº†åˆ‡å›è®­ç»ƒæ¨¡å¼

    # --------------------------------------------------
    def _build_camera(self, device, azim_deg):
        azim = math.radians(azim_deg)
        elev = math.radians(self.elev)
        cam_pos = torch.tensor([
            self.dist * math.cos(elev) * math.sin(azim),
            self.dist * math.sin(elev),
            self.dist * math.cos(elev) * math.cos(azim)
        ], device=device)
        target = torch.zeros(3, device=device)
        up = torch.tensor([0, 1, 0], device=device, dtype=torch.float32)

        z = torch.nn.functional.normalize(cam_pos - target, dim=-1)
        x = torch.nn.functional.normalize(torch.cross(up, z), dim=-1)
        y = torch.cross(z, x)
        R = torch.stack([x, y, z], dim=-1)          # [3,3]
        t = cam_pos
        K = torch.tensor([[max(self.h, self.w), 0, self.w / 2],
                          [0, max(self.h, self.w), self.h / 2],
                          [0, 0, 1]], device=device, dtype=torch.float32)
        return {
            "K": K.unsqueeze(0),      # [1, 3, 3]
            "R": R.unsqueeze(0),      # [1, 3, 3]
            "t": t.unsqueeze(0),      # [1, 3]
            "image_shape": (self.h, self.w)
        }